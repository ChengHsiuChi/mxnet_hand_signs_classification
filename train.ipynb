{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import nd, gluon, init, autograd, image\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data.vision import datasets, transforms\n",
    "from mxnet.gluon import data as gdata\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import mxnet\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Una\\hand_resize\"\n",
    "pic_list = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_aug = gdata.vision.transforms.RandomColorJitter(\n",
    "    brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1)\n",
    "\n",
    "augs = gdata.vision.transforms.Compose([\n",
    "    gdata.vision.transforms.RandomFlipLeftRight(), color_aug,\n",
    "    gdata.vision.transforms.RandomFlipTopBottom()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in pic_list:\n",
    "    with open(os.path.join(path,file), 'rb') as fp:\n",
    "        str_image = fp.read()\n",
    "    img = image.imdecode(str_image)\n",
    "    for j in range(3):\n",
    "        aug_img = augs(img)\n",
    "        img_save = Image.fromarray(aug_img.asnumpy(), 'RGB')\n",
    "        img_save.save(os.path.join(r\"C:\\Users\\Una\\hand_aug\", str(file[:-4])+str(j)+str(file[-4:])),\"JPEG\"  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"class0\",\"class1\",\"class2\",\"class3\",\"class4\",\"class5\"]\n",
    "ori_path = r\"C:\\Users\\Una\\data\\train\"\n",
    "toward_path = r\"SIGNS\\train_signs\"\n",
    "\n",
    "for class_i in classes:\n",
    "    class_path = os.path.join(ori_path,class_i)\n",
    "    class_pic_list = os.listdir(class_path)\n",
    "    for i in range(len(class_pic_list)):\n",
    "        img = Image.open(os.path.join(class_path,class_pic_list[i]))\n",
    "        img = img.resize((256,256))\n",
    "        img.save(os.path.join(toward_path,class_i,class_pic_list[i]) , 'JPEG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import nd, gluon, init, autograd, image\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data.vision import datasets, transforms\n",
    "from mxnet.gluon import data as gdata\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import mxnet\n",
    "from PIL import Image\n",
    "import mxnet as mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(output, label):\n",
    "    return (output.argmax(axis=1) ==\n",
    "            label.astype('float32')).mean().asscalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.ImageFolderDataset(r\"SIGNS\\train_signs\",flag=1,\n",
    "    transform = lambda data, label: (data.astype(np.float32)/255, label)).transform_first(transformer),\n",
    "    batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "test_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.ImageFolderDataset(r\"SIGNS\\test_signs\",flag=1,\n",
    "    transform = lambda data, label: (data.astype(np.float32)/255, label)).transform_first(transformer),\n",
    "    batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNetV1(\n",
      "  (output): Dense(2048 -> 1000, linear)\n",
      "  (features): HybridSequential(\n",
      "    (0): Conv2D(3 -> 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=64)\n",
      "    (2): Activation(relu)\n",
      "    (3): MaxPool2D(size=(3, 3), stride=(2, 2), padding=(1, 1), ceil_mode=False)\n",
      "    (4): HybridSequential(\n",
      "      (0): BottleneckV1(\n",
      "        (downsample): HybridSequential(\n",
      "          (0): Conv2D(64 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=256)\n",
      "        )\n",
      "        (body): HybridSequential(\n",
      "          (0): Conv2D(64 -> 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=64)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv2D(64 -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=64)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv2D(64 -> 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (7): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=256)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckV1(\n",
      "        (body): HybridSequential(\n",
      "          (0): Conv2D(256 -> 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=64)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv2D(64 -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=64)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv2D(64 -> 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (7): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=256)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckV1(\n",
      "        (body): HybridSequential(\n",
      "          (0): Conv2D(256 -> 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=64)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv2D(64 -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=64)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv2D(64 -> 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (7): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=256)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): HybridSequential(\n",
      "      (0): BottleneckV1(\n",
      "        (downsample): HybridSequential(\n",
      "          (0): Conv2D(256 -> 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=512)\n",
      "        )\n",
      "        (body): HybridSequential(\n",
      "          (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "          (1): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=128)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=128)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (7): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=512)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckV1(\n",
      "        (body): HybridSequential(\n",
      "          (0): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=128)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=128)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (7): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=512)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckV1(\n",
      "        (body): HybridSequential(\n",
      "          (0): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=128)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=128)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (7): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=512)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckV1(\n",
      "        (body): HybridSequential(\n",
      "          (0): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=128)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=128)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (7): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=512)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): HybridSequential(\n",
      "      (0): BottleneckV1(\n",
      "        (downsample): HybridSequential(\n",
      "          (0): Conv2D(512 -> 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=1024)\n",
      "        )\n",
      "        (body): HybridSequential(\n",
      "          (0): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "          (1): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=256)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=256)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (7): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=1024)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckV1(\n",
      "        (body): HybridSequential(\n",
      "          (0): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=256)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=256)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (7): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=1024)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckV1(\n",
      "        (body): HybridSequential(\n",
      "          (0): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=256)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=256)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (7): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=1024)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckV1(\n",
      "        (body): HybridSequential(\n",
      "          (0): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=256)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=256)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (7): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=1024)\n",
      "        )\n",
      "      )\n",
      "      (4): BottleneckV1(\n",
      "        (body): HybridSequential(\n",
      "          (0): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=256)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=256)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (7): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=1024)\n",
      "        )\n",
      "      )\n",
      "      (5): BottleneckV1(\n",
      "        (body): HybridSequential(\n",
      "          (0): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=256)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=256)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (7): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=1024)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): HybridSequential(\n",
      "      (0): BottleneckV1(\n",
      "        (downsample): HybridSequential(\n",
      "          (0): Conv2D(1024 -> 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=2048)\n",
      "        )\n",
      "        (body): HybridSequential(\n",
      "          (0): Conv2D(1024 -> 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "          (1): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=512)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv2D(512 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=512)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv2D(512 -> 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (7): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=2048)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckV1(\n",
      "        (body): HybridSequential(\n",
      "          (0): Conv2D(2048 -> 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=512)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv2D(512 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=512)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv2D(512 -> 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (7): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=2048)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckV1(\n",
      "        (body): HybridSequential(\n",
      "          (0): Conv2D(2048 -> 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=512)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv2D(512 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=512)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv2D(512 -> 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (7): BatchNorm(fix_gamma=False, momentum=0.9, use_global_stats=False, eps=1e-05, axis=1, in_channels=2048)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (8): GlobalAvgPool2D(size=(1, 1), stride=(1, 1), padding=(0, 0), ceil_mode=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from mxnet.gluon.model_zoo.vision import resnet50_v1\n",
    "pretrained_net = resnet50_v1(pretrained=True)\n",
    "print(pretrained_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = resnet50_v1(classes=6)\n",
    "net.features = pretrained_net.features\n",
    "net.output.initialize(init.Xavier())\n",
    "\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.05})\n",
    "best_acc = 0\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc, valid_acc = 0., 0., 0.\n",
    "    tic = time.time()\n",
    "    #for batch_idx, (data, label) in enumerate(data_loader):\n",
    "    for (data, label) in train_data:\n",
    "        with autograd.record():\n",
    "            output = net(data)\n",
    "            loss = softmax_cross_entropy(output,label)\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        trainer.step(batch_size)\n",
    "        # calculate training metrics\n",
    "        train_loss += loss.mean().asscalar()\n",
    "        train_acc += acc(output, label)\n",
    "        \n",
    "    if(np.isnan(train_loss)):\n",
    "        print(\"Training ends\")\n",
    "        break\n",
    "    \n",
    "    # calculate validation accuracy\n",
    "    for data, label in test_data:\n",
    "        valid_acc += acc(net(data), label)\n",
    "    if(valid_acc > best_acc):\n",
    "        best_acc = valid_acc\n",
    "        net.save_parameters('net_resnet50_v1.params')  \n",
    "    print(\"Epoch %d: loss %.3f, train acc %.3f, test acc %.3f, in %.1f sec\" % ( \n",
    "            epoch, train_loss/len(train_data), train_acc/len(train_data),\n",
    "            valid_acc/len(test_data), time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mxnet",
   "language": "python",
   "name": "mxnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
